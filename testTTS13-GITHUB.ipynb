{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "################################################################\n",
    "################################################################\n",
    "################################################################\n",
    "################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "    *************************************************************** \n",
      "    *************************************************************** \n",
      "    *************************************************************** \n",
      " Input file:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/System_800xA_Summary.pdf_extractedText_4.csv\n",
      "\n",
      "    *************************************************************** \n",
      "    *************************************************************** \n",
      "    ***************************************************************  \n",
      "\n",
      "\n",
      "\n",
      "\t# Rows read into dataframe = 5\n",
      "\n",
      "\t# Rows Skipped = 50\n",
      "\n",
      "\tdfIn.shape = (5, 1)\n"
     ]
    }
   ],
   "source": [
    "#######################################################################################\n",
    "###  Take the cleaned up extracted PDF contents CSV file as input data.\n",
    "###  Convert the sentence to wav audio  in 16kHz, mono, PCM coding.\n",
    "###  Save the audio files.\n",
    "###  Create the CSV file required by Deepspeech training.\n",
    "###  Create additional CSV file which also includes the short name of the voice type\n",
    "###         -- note this file is not used for for Deepspeech and only for reference.\n",
    "###\n",
    "###  NOTES: Expects 13 command line parameters (including the script name)\n",
    "###         Handles 503 error by making up to 3 API calls for the same conversion.\n",
    "###         Handles 429 error by exiting prematurely and sets a flag to indicate problem occurred.\n",
    "#######################################################################################\n",
    "#\n",
    "#\n",
    "############################################################\n",
    "#\n",
    "#\n",
    "## https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/Samples-Http/Python/TTSSample.py\n",
    "import os, requests, time\n",
    "import pandas as pd\n",
    "from xml.etree import ElementTree\n",
    "from datetime import datetime\n",
    "from random import randint\n",
    "import logging\n",
    "#\n",
    "pd.set_option('max_columns', 500)\n",
    "pd.set_option('max_colwidth', -1)\n",
    "pd.set_option('max_rows', 500)\n",
    "#\n",
    "## https://www.patricksoftwareblog.com/python-logging-tutorial/\n",
    "logFilenameWithPath = '/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavsCsvFile/LOG_testTTS13.log'\n",
    "logging.basicConfig(level=logging.WARNING, filename=logFilenameWithPath,                      \\\n",
    "    filemode='w', format='%(asctime)s : %(message)s')\n",
    "#    filemode='w', format='')\n",
    "#    filemode='w', format='%(asctime)s %(levelname)s:%(message)s')\n",
    "#\n",
    "## track how many characters were sent to Azure TTS\n",
    "## Paid version allows 20 concurrent requests  (free allows only 1)\n",
    "## https://azure.microsoft.com/en-us/pricing/details/cognitive-services/speech-services/\n",
    "## Costs for Standard TTS:\n",
    "## Paid version - 4$ per 1 million characters\n",
    "overallCharCountTrack = 0\n",
    "#\n",
    "## Read the input file.\n",
    "#\n",
    "# The file has these three columns in a csv format:\n",
    "#             sentence,pageNum,sentenceLen\n",
    "#\n",
    "inFilePath = '/home/rohit/dpspTraining/data/azure/pdfExtraction/'\n",
    "inFileName = 'System_800xA_Summary.pdf_extractedText_4.csv'\n",
    "inPdFile = inFilePath + inFileName\n",
    "#\n",
    "## The output file expected for the Deepspeech training has three columns:\n",
    "#             wav_filename,wav_filesize,transcript\n",
    "#\n",
    "print(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "print(f\" Input file:\\n{inPdFile}\")\n",
    "print(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    ***************************************************************  \\n\\n\")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    *************************************************************** \")\n",
    "logging.warning(f\" Input file:\\n{inPdFile}\")\n",
    "logging.warning(f\"\\n    *************************************************************** \\n    *************************************************************** \\n    ***************************************************************  \\n\\n\")\n",
    "#\n",
    "colsToReadIn = ['sentence']\n",
    "#\n",
    "# set rowsToRead = -1 to read the whole dataframe in one shot, else specify the number accordingly\n",
    "rowsToRead = 5\n",
    "rowsToSkip = 50\n",
    "if rowsToRead == -1:\n",
    "    dfIn = pd.read_csv( inPdFile, sep=',', usecols = colsToReadIn, skiprows = range(1, rowsToSkip+1), header = 0, low_memory=False )\n",
    "else:\n",
    "    dfIn = pd.read_csv( inPdFile, sep=',', nrows = rowsToRead, usecols = colsToReadIn, skiprows = range(1, rowsToSkip+1), header = 0, low_memory=False )\n",
    "#\n",
    "print(f'\\n\\t# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "logging.warning(f'\\n\\t# Rows read into dataframe = {rowsToRead if rowsToRead != -1 else \"all the rows\"}')\n",
    "print(f\"\\n\\t# Rows Skipped = {rowsToSkip}\")\n",
    "logging.warning(f\"\\n\\t# Rows Skipped = {rowsToSkip}\")\n",
    "print(f\"\\n\\tdfIn.shape = {dfIn.shape}\")\n",
    "logging.warning(f\"\\n\\tdfIn.shape = {dfIn.shape}\\n\")\n",
    "#\n",
    "#\n",
    "############################################################\n",
    "#\n",
    "#\n",
    "## https://github.com/Azure-Samples/Cognitive-Speech-TTS/blob/master/Samples-Http/Python/TTSSample.py\n",
    "class TextToSpeech(object):\n",
    "    #\n",
    "    def __init__(self, subscription_key):\n",
    "        self.subscription_key = subscription_key\n",
    "        self.tts = None   ##  the text to be converted to audio -- defaulting the value to None\n",
    "        self.timestr = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        self.access_token = None\n",
    "        self.access_token_startTime = None\n",
    "    #\n",
    "    #The TTS endpoint requires an access token. This method exchanges your\n",
    "    #subscription key for an access token that is valid for ten minutes.\n",
    "    #\n",
    "    def get_token(self):\n",
    "        #fetch_token_url = \"https://westus.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        fetch_token_url = \"https://westeurope.api.cognitive.microsoft.com/sts/v1.0/issueToken\"\n",
    "        headers = {\n",
    "            'Ocp-Apim-Subscription-Key': self.subscription_key\n",
    "        }\n",
    "        response = requests.post(fetch_token_url, headers=headers)\n",
    "        self.access_token = str(response.text)\n",
    "        self.access_token_startTime = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "    #\n",
    "    def check_tokenGenerationTime_and_regenerateIfRequired(self, thresholdInSecs = 540):\n",
    "        timeNow = time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "        s_tg = time.strptime(self.access_token_startTime, \"%Y%m%d-%H%M%S\")  # struct_time of token generation time\n",
    "        s_now = time.strptime(timeNow, \"%Y%m%d-%H%M%S\")  # struct_time of now time\n",
    "        timeDiff = time.mktime(s_now) - time.mktime(s_tg) ## time since token generation in seconds\n",
    "        if timeDiff > thresholdInSecs: # azure documentation states token valid for 10 mins, so default 9*60 = 540 secs\n",
    "            logging.warning(f\"\\nRequesting new access token automatically.\")\n",
    "            logging.warning(f\"Old token: Start time = {self.access_token_startTime}\\nTime now = {timeNow}\")\n",
    "            logging.warning(f\"Time Difference (secs) since last generation= {timeDiff}\")\n",
    "            #print(f\"\\nOld access_token = \\n{self.access_token}\\n\")\n",
    "            logging.warning(f\"\\nOld access_token = \\n{self.access_token}\\n\")\n",
    "            self.get_token()\n",
    "            #print(f\"\\nNew Access Token received = \\n{self.access_token}\")\n",
    "            logging.warning(f\"\\nNew Access Token received = \\n{self.access_token}\")\n",
    "            #print(f\"\\nNew Access Token Start Time = \\n{self.access_token_startTime}\\n\")\n",
    "            logging.warning(f\"\\nNew Access Token Start Time = \\n{self.access_token_startTime}\\n\")\n",
    "    #\n",
    "    def save_audio(self, inVoiceTypeShortName = '', fileNumber = 1, wavFilePath = ''):\n",
    "        #### Inputs:\n",
    "        ####       the ShortName of the voice type to be used.\n",
    "        ####       the file number to include in the filename.\n",
    "        ####       the absolute path where to save the audio file.\n",
    "        #### Returns:\n",
    "        ####       the status code (should be 200 if all good).\n",
    "        ####       the audio file name created.\n",
    "        #\n",
    "        base_url = 'https://westeurope.tts.speech.microsoft.com/'\n",
    "        path = 'cognitiveservices/v1'\n",
    "        constructed_url = base_url + path\n",
    "        headers = {\n",
    "            'Authorization': 'Bearer ' + self.access_token,\n",
    "            'Content-Type': 'application/ssml+xml',\n",
    "            #'X-Microsoft-OutputFormat': 'riff-24khz-16bit-mono-pcm',\n",
    "            'X-Microsoft-OutputFormat': 'riff-16khz-16bit-mono-pcm', # Deepspeech needs 16kHz, mono, PCM encoded wav files\n",
    "            'User-Agent': 'YOUR_RESOURCE_NAME'\n",
    "        }\n",
    "        xml_body = ElementTree.Element('speak', version='1.0')\n",
    "        xml_body.set('{http://www.w3.org/XML/1998/namespace}lang', 'en-us')\n",
    "        voice = ElementTree.SubElement(xml_body, 'voice')\n",
    "        voice.set('{http://www.w3.org/XML/1998/namespace}lang', 'en-US')\n",
    "        #voice.set('name', 'en-US-Guy24kRUS') # Short name for 'Microsoft Server Speech Text to Speech Voice (en-US, Guy24KRUS)'\n",
    "        voice.set('name', inVoiceTypeShortName) # Short name for 'Microsoft Server Speech Text to Speech Voice\n",
    "        voice.text = self.tts\n",
    "        body = ElementTree.tostring(xml_body)\n",
    "        #\n",
    "        ## sometimes azure response = 503\n",
    "        ##    https://docs.microsoft.com/en-us/rest/api/searchservice/http-status-codes\n",
    "        ##    Solution: make API call up to 3 times with random delay\n",
    "        for _ in range(3):\n",
    "            counters['countApiCallsMade'] += 1\n",
    "            response = requests.post(constructed_url, headers=headers, data=body)\n",
    "            if response.status_code != 503:\n",
    "                break\n",
    "            sleep503Time = randint(3, 10)\n",
    "            #print(f\"\\nAure response = 503, so sleeping for {sleep503Time} seconds.\\n\")\n",
    "            logging.warning(f\"\\nAure response = 503, so sleeping for {sleep503Time} seconds.\\n\")\n",
    "            time.sleep(sleep503Time)\n",
    "            #\n",
    "        #\n",
    "        #If a success response is returned, then the binary audio is written to the file.\n",
    "        #\n",
    "        outWavFile = '' # if conversion failed then this will remain empty string\n",
    "        # if the conversion is successful then status code will be 200.\n",
    "        if response.status_code == 200:\n",
    "            ## the wav file is created at the location sent during function call via wavFilePath variable\n",
    "            ##     example of how filename will look: azureSTT_7_en-CA-HeatherRUS_20191119-121233.wav\n",
    "            outWavFile = 'azureSTT_' + str(fileNumber) + '_' + inVoiceTypeShortName + '_' + time.strftime(\"%Y%m%d-%H%M%S\") + '.wav'\n",
    "            with open(wavFilePath + outWavFile, 'wb') as audio:\n",
    "                audio.write(response.content)\n",
    "                #print(f\"\\nSuccess -- file number = {fileNumber}\\nfile created: {outWavFile}\")\n",
    "                logging.warning(f\"\\nSuccess -- file number = {fileNumber}\\nfile created: {outWavFile}\")\n",
    "                counters['countAudioConversionSuccess'] += 1\n",
    "        else:\n",
    "            #print(f\"\\nFAILED -- file number = {fileNumber}\\nresponse.status_code: {str(response.status_code)}\\nsentence=\\n{self.tts}\")\n",
    "            logging.warning(f\"\\nFAILED -- file number = {fileNumber}\\nresponse.status_code: {str(response.status_code)}\\nsentence=\\n{self.tts}\")\n",
    "            counters['countAudioConversionFailed'] += 1\n",
    "        #\n",
    "        return response.status_code, outWavFile\n",
    "    #\n",
    "    def get_voices_list(self):\n",
    "        #base_url = 'https://westus.tts.speech.microsoft.com/'\n",
    "        base_url = 'https://westeurope.tts.speech.microsoft.com/'\n",
    "        path = 'cognitiveservices/voices/list'\n",
    "        constructed_url = base_url + path\n",
    "        headers = {\n",
    "            'Authorization': 'Bearer ' + self.access_token,\n",
    "        }\n",
    "        response = requests.get(constructed_url, headers=headers)\n",
    "        if response.status_code == 200:\n",
    "            print(\"\\nAvailable voices: \\n\" + response.text)\n",
    "        else:\n",
    "            print(\"\\nStatus code: \" + str(response.status_code) + \"\\nSomething went wrong. Check your subscription key and headers.\\n\")\n",
    "    #\n",
    "    ### my code\n",
    "    def set_text_to_convert(self, inText):\n",
    "        if isinstance(inText, str):\n",
    "            self.tts = inText\n",
    "            return True\n",
    "        else:\n",
    "            return False\n",
    "#\n",
    "#\n",
    "############################################################\n",
    "#\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Wav files will be saved here:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavs/\n",
      "\n",
      "Output CSV files will be saved here:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavsCsvFile/\n",
      "\n",
      "\n",
      "\n",
      "# Voice Short Names input = 13.\n",
      "\n",
      "The names of the voices are:\n",
      "\ten-AU-Catherine\n",
      "\ten-AU-HayleyRUS\n",
      "\ten-CA-HeatherRUS\n",
      "\ten-CA-Linda\n",
      "\ten-GB-George-Apollo\n",
      "\ten-GB-HazelRUS\n",
      "\ten-GB-Susan-Apollo\n",
      "\ten-IN-Heera-Apollo\n",
      "\ten-IN-PriyaRUS\n",
      "\ten-IN-Ravi-Apollo\n",
      "\ten-US-BenjaminRUS\n",
      "\ten-US-JessaRUS\n",
      "\ten-US-ZiraRUS\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "    ***************************************************************\n",
      "    ***************************************************************\n",
      "\tProcessing input data....\n",
      "\n",
      "\n",
      "    ***************************************************************\n",
      "    ***************************************************************\n",
      "\n",
      "\n",
      "\n",
      " ----------------------- **** Processing sentence # 1 *** -----------------------\n",
      "Sentence =\n",
      "abb provides asset management solutions that present realtime asset information seamlessly and in the proper context to operations maintenance engineering and management\n",
      "\n",
      " ----------------------- **** Processing sentence # 3 *** -----------------------\n",
      "Sentence =\n",
      "these activities can be employed regardless of industry\n",
      "\n",
      "\n",
      "Sentence+voiceType processing done.\n",
      "processingReturnCode = 0\n",
      "\n",
      "\n",
      "\n",
      "Creating output files...\n",
      "\n",
      "\n",
      "\n",
      "Full Data CSV file created here:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavsCsvFile/System_800xA_Summary.pdf_extractedText_4_NOT_forDS.csv\n",
      "\n",
      "Deepspeech training CSV file created here:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavsCsvFile/System_800xA_Summary.pdf_extractedText_4_forDS.csv\n",
      "\n",
      "WAV files location:\n",
      "/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavs/\n",
      "\n",
      "\n",
      " ########## SUMMARY ######### SUMMARY ######### SUMMARY #########\n",
      "\n",
      "\n",
      "# Rows Read = 5\t\t# Rows Skipped = 50\n",
      "\n",
      "# Sentences in input file                    = 5\n",
      "\n",
      "# Voices types input                         = 13\n",
      "\n",
      "# Sentences read in                          = 5\n",
      "\n",
      "# Invalid Sentences                          = 0\n",
      "\n",
      "  There should be these number of rows in the output file, if all went well:\n",
      "    numSentences * numVoiceTypes               = 65\n",
      "\n",
      "  counters['countRowsWrittenToDfOut']        = 65\n",
      "\n",
      "# rows in dfOut                              = 65\n",
      "\n",
      "# Successful audio conversion                = 65\n",
      "\n",
      "# Failed audio conversion                    = 0\n",
      "\n",
      "# API calls made to Azure                    = 65\n",
      "\n",
      "# Characters processed                       = 8853\n",
      "\n",
      "Processing return code                       = 0\n",
      "\n",
      "  Status flag for 429 error                  = False\n",
      "\n",
      "\n",
      "\n",
      "Normal exit\n",
      "\n"
     ]
    }
   ],
   "source": [
    "## The output file expected for the Deepspeech training has three columns:\n",
    "#             wav_filename,wav_filesize,transcript\n",
    "#\n",
    "outWavFilesPath = '/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavs/'\n",
    "#\n",
    "outFilePath = '/home/rohit/dpspTraining/data/azure/pdfExtraction/convertedWavsCsvFile/'\n",
    "#\n",
    "# file for Deepspeech -- only 3 columns\n",
    "outFileName4Deepspeech = 'System_800xA_Summary.pdf_extractedText_4_forDS.csv'\n",
    "# file for full data -- all 4 columns -- including the Short Name of Voice Type\n",
    "outFileNameFullData = 'System_800xA_Summary.pdf_extractedText_4_NOT_forDS.csv'\n",
    "#\n",
    "## amount of time after which to request a new token\n",
    "accessTokenRecheckInSeconds = 300\n",
    "## number of api calls after which to sleep\n",
    "apiCallThrottleLimit = 20\n",
    "## time in seconds to sleep during throttling\n",
    "apiCallThrottleSleepTime = 60\n",
    "#\n",
    "## how frequently should it print status to console -- based on row read in from input file\n",
    "statusRowPrintFreq = 3\n",
    "#\n",
    "counters = { 'countRowsReadIn': 0 , 'countRowsWrittenToDfOut': 0 , 'countAudioConversionSuccess': 0 , \\\n",
    "            'countAudioConversionFailed': 0 , 'countInvalidSentences': 0, 'countApiCallsMade': 0}\n",
    "#\n",
    "## When the final output CSV file is written for Deepspeech, then the voiceShortName will not be included.\n",
    "#\n",
    "dfOutColumns = [ 'voiceShortName' , 'wav_filename' , 'wav_filesize' , 'transcript']\n",
    "#\n",
    "dfOutColumnsDtypes = [str, str, int, str]\n",
    "dfOut = pd.DataFrame(columns = dfOutColumns)\n",
    "#dfOut = dfOut.astype({\"wav_filename\": str, \"wav_filesize\": int, 'transcript': str})\n",
    "dfOut = dfOut.astype(dict(zip(dfOutColumns, dfOutColumnsDtypes)))\n",
    "#\n",
    "## add slash at end if not there already\n",
    "if outFilePath[-1] != '/':\n",
    "    outFilePath = outFilePath + '/'\n",
    "if outWavFilesPath[-1] != '/':\n",
    "    outWavFilesPath = outWavFilesPath + '/'\n",
    "#\n",
    "print(f\"\\nWav files will be saved here:\\n{outWavFilesPath}\")\n",
    "logging.warning(f\"\\nWav files will be saved here:\\n{outWavFilesPath}\")\n",
    "#\n",
    "print(f\"\\nOutput CSV files will be saved here:\\n{outFilePath}\\n\\n\")\n",
    "logging.warning(f\"\\nOutput CSV files will be saved here:\\n{outFilePath}\\n\\n\")\n",
    "#\n",
    "## create the object for the TTS processing\n",
    "app = TextToSpeech('xxxxxxxxxxxxxxxxxxxxxxxxxxxxxxxx')\n",
    "app.get_token()\n",
    "#print(f\"\\nFirst time Access Token = \\n{app.access_token}\")\n",
    "logging.warning(f\"\\nFirst time Access Token = \\n{app.access_token}\")\n",
    "#print(f\"\\nFirst time Access Token Start Time = \\n{app.access_token_startTime}\\n\")\n",
    "logging.warning(f\"\\nFirst time Access Token Start Time = \\n{app.access_token_startTime}\\n\")\n",
    "#\n",
    "#voiceTypeShortNameList = [ 'en-AU-Catherine', 'en-AU-HayleyRUS', 'en-CA-HeatherRUS' ]\n",
    "voiceTypeShortNameList = [ 'en-AU-Catherine', 'en-AU-HayleyRUS', 'en-CA-HeatherRUS', 'en-CA-Linda', \\\n",
    "                          'en-GB-George-Apollo', 'en-GB-HazelRUS', 'en-GB-Susan-Apollo', \\\n",
    "                          'en-IN-Heera-Apollo', 'en-IN-PriyaRUS', 'en-IN-Ravi-Apollo', \\\n",
    "                          'en-US-BenjaminRUS', 'en-US-JessaRUS', 'en-US-ZiraRUS' ]\n",
    "print(f\"\\n# Voice Short Names input = {len(voiceTypeShortNameList)}.\\n\\nThe names of the voices are:\")\n",
    "logging.warning(f\"\\n# Voice Short Names input = {len(voiceTypeShortNameList)}.\\n\\nThe names of the voices are:\")\n",
    "for voiceType in voiceTypeShortNameList:\n",
    "    print(f\"\\t{voiceType}\")\n",
    "    logging.warning(f\"\\t{voiceType}\")\n",
    "print(f\"\\n\\n\")\n",
    "logging.warning(f\"\\n\\n\")\n",
    "#\n",
    "myStr = f'\\n' + \\\n",
    "    f'\\n    ***************************************************************' * 2 + \\\n",
    "    f'\\n\\tProcessing input data....\\n\\n' + \\\n",
    "    f'\\n    ***************************************************************' * 2 + \\\n",
    "    f'\\n\\n'\n",
    "print(f\"{myStr}\")\n",
    "logging.warning(f\"{myStr}\")\n",
    "#\n",
    "## fileNumber = 0, it is increased in loop immediately and we want first sentence\n",
    "##         to correspond to audio filenames with file number 1\n",
    "fileNumber = rowsToSkip\n",
    "#\n",
    "## this should be remain 0 ideally, the flag for 429 will tell if 429 error occurred\n",
    "processingReturnCode = 0\n",
    "#\n",
    "## ideally this should never have been set to True\n",
    "flagRc429Encountered = False  ## check any Azure call had 429 response code\n",
    "#\n",
    "## start processing the sentences from dfin for each voice type required\n",
    "for row in dfIn.itertuples():\n",
    "    #\n",
    "    if processingReturnCode != 0 or flagRc429Encountered == True:\n",
    "        break\n",
    "    #\n",
    "    counters['countRowsReadIn'] += 1\n",
    "    fileNumber += 1  ## same file number should remain for a particular sentence\n",
    "    #\n",
    "    ## Convert named tuple to dictionary\n",
    "    ## using as per this link: https://thispointer.com/pandas-6-different-ways-to-iterate-over-rows-in-a-dataframe-update-while-iterating-row-by-row/\n",
    "    dictRow = row._asdict()\n",
    "    #\n",
    "    textToConvert = dictRow['sentence']\n",
    "    #\n",
    "    ## log each sentence , but print a status only as per input frequency\n",
    "    myStr = f\"\\n ----------------------- **** Processing sentence # {counters['countRowsReadIn']} *** -----------------------\" + \\\n",
    "            f\"\\nSentence =\\n{textToConvert}\"\n",
    "    logging.warning(f\"{myStr}\")\n",
    "    ## print which row is being processed every so long\n",
    "    if counters['countRowsReadIn'] % statusRowPrintFreq == 0 or counters['countRowsReadIn'] == 1:\n",
    "        print(f\"{myStr}\")\n",
    "    #\n",
    "    if textToConvert is not None and textToConvert != '':\n",
    "        if app.set_text_to_convert(textToConvert) == False:\n",
    "            print(f\"\\n\\nFatal Error: Problem setting text in the app object.\\n\\n\")\n",
    "            logging.warning(f\"\\n\\nFatal Error: Problem setting text in the app object.\\n\\n\")\n",
    "            processingReturnCode = 100\n",
    "            break\n",
    "    else:\n",
    "        logging.warning(f\"\\nSentence was None or empty string. Continuing to next sentence.\\n\")\n",
    "        counters['countInvalidSentences'] += 1\n",
    "        continue ## move to the next sentence\n",
    "    #\n",
    "    ## sentence is fine and set in the app object, so now convert for each type of voice\n",
    "    #\n",
    "    for idxVoiceType, voiceTypeShortName in enumerate(voiceTypeShortNameList):\n",
    "        #print(f\"\\n **** Voice = {idxVoiceType + 1} *** \\t\\tvoice Short Name = {voiceTypeShortName}\")\n",
    "        logging.warning(f\"\\n **** Voice = {idxVoiceType + 1} *** \\t\\tvoice Short Name = {voiceTypeShortName}\")\n",
    "        #\n",
    "        ## throttling to avoid response 429 from Azure\n",
    "        ## https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/faq-text-to-speech\n",
    "        if counters['countApiCallsMade'] != 0 and counters['countApiCallsMade'] % apiCallThrottleLimit == 0:\n",
    "            #print(f\"\\nSleeping for {apiCallThrottleSleepTime} seconds, api calls made so far = {counters['countApiCallsMade']}\")\n",
    "            logging.warning(f\"\\nSleeping for {apiCallThrottleSleepTime} seconds, api calls made so far = {counters['countApiCallsMade']}\")\n",
    "            time.sleep(apiCallThrottleSleepTime)\n",
    "            #print(f\"\\nFinished sleep, continuing....\\n\")\n",
    "            logging.warning(f\"\\nFinished sleep, continuing....\\n\")\n",
    "        #\n",
    "        ## check the current token issue time. If more than threshold time has passed, then get new token again.\n",
    "        app.check_tokenGenerationTime_and_regenerateIfRequired(accessTokenRecheckInSeconds)\n",
    "        #\n",
    "        ## make api call to convert audio. also increments the counters for audio conversion\n",
    "        ##      success, failed, api calls made.\n",
    "        overallCharCountTrack += len(textToConvert)\n",
    "        try:\n",
    "            appSaveAudioRespCode, savedWavFilename = app.save_audio( voiceTypeShortName, fileNumber, outWavFilesPath )\n",
    "        except:\n",
    "            ## unexpected issue (e.g. had a OSError: Tunnel connection failed: 502 Could not relay message upstream)\n",
    "            ##     this killed process midway -> no output CSV file and NO REJOIN with main process.\n",
    "            ##     so main process did not proceed and waits infinitely.\n",
    "            ## if there are already any entries in dfOut then write to CSV file and rejoin the main process\n",
    "            processingReturnCode = 11000 ## using huge value\n",
    "            myStr = f\"\\n\" + \\\n",
    "                    \"\\n ------ Unhandled exception occurred during save_audio call ------ \" * 2 + \\\n",
    "                    \"\\n\"\n",
    "            print(f\"{myStr}\")\n",
    "            logging.warning(f\"{myStr}\")\n",
    "            break\n",
    "            #\n",
    "        ## azure api call returns with response code 200 if all is ok.\n",
    "        ##       overwriting processingReturnCode only if it is serious.\n",
    "        if appSaveAudioRespCode != 200:\n",
    "            if appSaveAudioRespCode == 429:\n",
    "                flagRc429Encountered = True\n",
    "                break\n",
    "            #\n",
    "            ## its not 429, something serious\n",
    "            #print(f\"\\n\\nProblem with audio conversion. Azure response Status Code = {appSaveAudioRespCode}\\n\\n\")\n",
    "            logging.warning(f\"\\n\\nProblem with audio conversion. Azure response Status Code = {appSaveAudioRespCode}\\n\\n\")\n",
    "            processingReturnCode = appSaveAudioRespCode\n",
    "            break\n",
    "        #\n",
    "        ## no major problems encountered so far, get the filesize\n",
    "        try:\n",
    "            ## get the filesize and make entry in dataframe for output file\n",
    "            fullPathWavFile = outWavFilesPath + savedWavFilename\n",
    "            wavFileSize = os.path.getsize(fullPathWavFile)\n",
    "            dfOutColumnsData = [ voiceTypeShortName, fullPathWavFile , wavFileSize , textToConvert ]\n",
    "            dfOut = dfOut.append( dict(zip(dfOutColumns, dfOutColumnsData)) , ignore_index = True)\n",
    "            counters['countRowsWrittenToDfOut'] += 1\n",
    "        except:\n",
    "            print(f\"\\n\\nFatal Error: Problem getting the wav file size or making entry for output dataframe.\\n\\n\")\n",
    "            logging.warning(f\"\\n\\nFatal Error: Problem getting the wav file size or making entry for output dataframe.\\n\\n\")\n",
    "            processingReturnCode = 300\n",
    "            break\n",
    "        #\n",
    "    #\n",
    "#\n",
    "if processingReturnCode != 0:\n",
    "    print(f\"\\n\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\")\n",
    "    logging.warning(f\"\\n\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\\nFatal Error: ### PROBLEM ### PROBLEM ### PROBLEM ### PROBLEM ###\")\n",
    "#\n",
    "print(f\"\\n\\nSentence+voiceType processing done.\\nprocessingReturnCode = {processingReturnCode}\\n\\n\")\n",
    "logging.warning(f\"\\n\\nSentence+voiceType processing done.\\nprocessingReturnCode = {processingReturnCode}\\n\\n\")\n",
    "#\n",
    "print(f\"\\nCreating output files...\\n\")\n",
    "logging.warning(f\"\\nCreating output files...\\n\")\n",
    "#\n",
    "## Write full output file including voice type short name\n",
    "dfOut.to_csv(outFilePath + outFileNameFullData, index = False)\n",
    "#\n",
    "## Write output file for Deepspeech training -- only the three required columns\n",
    "dfOutForFile = dfOut[['wav_filename' , 'wav_filesize' , 'transcript']]\n",
    "dfOutForFile.to_csv(outFilePath + outFileName4Deepspeech, index = False)\n",
    "#\n",
    "# Print the summary info\n",
    "#\n",
    "print(f\"\\n\\nFull Data CSV file created here:\\n{outFilePath + outFileNameFullData}\")\n",
    "print(f\"\\nDeepspeech training CSV file created here:\\n{outFilePath + outFileName4Deepspeech}\")\n",
    "print(f\"\\nWAV files location:\\n{outWavFilesPath}\")\n",
    "#\n",
    "print(f\"\\n\\n ########## SUMMARY ######### SUMMARY ######### SUMMARY #########\\n\")\n",
    "print(f\"\\n# Rows Read = {rowsToRead}\\t\\t# Rows Skipped = {rowsToSkip}\")\n",
    "print(f\"\\n# Sentences in input file                    = {len(dfIn)}\")\n",
    "print(f\"\\n# Voices types input                         = {len(voiceTypeShortNameList)}\")\n",
    "print(f\"\\n# Sentences read in                          = {counters['countRowsReadIn']}\")\n",
    "print(f\"\\n# Invalid Sentences                          = {counters['countInvalidSentences']}\")\n",
    "print(f\"\\n  There should be these number of rows in the output file, if all went well:\")\n",
    "print(f\"    numSentences * numVoiceTypes               = {len(dfIn) * len(voiceTypeShortNameList)}\")\n",
    "print(f\"\\n  counters['countRowsWrittenToDfOut']        = {counters['countRowsWrittenToDfOut']}\")\n",
    "print(f\"\\n# rows in dfOut                              = {len(dfOut)}\")\n",
    "print(f\"\\n# Successful audio conversion                = {counters['countAudioConversionSuccess']}\")\n",
    "print(f\"\\n# Failed audio conversion                    = {counters['countAudioConversionFailed']}\")\n",
    "print(f\"\\n# API calls made to Azure                    = {counters['countApiCallsMade']}\")\n",
    "print(f\"\\n# Characters processed                       = {overallCharCountTrack}\")\n",
    "print(f\"\\nProcessing return code                       = {processingReturnCode}\")\n",
    "print(f\"\\n  Status flag for 429 error                  = {flagRc429Encountered}\")\n",
    "#\n",
    "logging.warning(f\"\\n\\nFull Data CSV file created here:\\n{outFilePath + outFileNameFullData}\")\n",
    "logging.warning(f\"\\nDeepspeech training CSV file created here:\\n{outFilePath + outFileName4Deepspeech}\")\n",
    "logging.warning(f\"\\nWAV files location:\\n{outWavFilesPath}\")\n",
    "#\n",
    "logging.warning(f\"\\n\\n ########## SUMMARY ######### SUMMARY ######### SUMMARY #########\\n\")\n",
    "logging.warning(f\"\\n# Rows Read = {rowsToRead}\\t\\t# Rows Skipped = {rowsToSkip}\")\n",
    "logging.warning(f\"\\n# Sentences in input file                    = {len(dfIn)}\")\n",
    "logging.warning(f\"\\n# Voices types input                         = {len(voiceTypeShortNameList)}\")\n",
    "logging.warning(f\"\\n# Sentences read in                          = {counters['countRowsReadIn']}\")\n",
    "logging.warning(f\"\\n# Invalid Sentences                          = {counters['countInvalidSentences']}\")\n",
    "logging.warning(f\"\\n  There should be these number of rows in the output file:\")\n",
    "logging.warning(f\"    numSentences * numVoiceTypes               = {len(dfIn) * len(voiceTypeShortNameList)}\")\n",
    "logging.warning(f\"\\n  counters['countRowsWrittenToDfOut']        = {counters['countRowsWrittenToDfOut']}\")\n",
    "logging.warning(f\"\\n# rows in dfOut                              = {len(dfOut)}\")\n",
    "logging.warning(f\"\\n# Successful audio conversion                = {counters['countAudioConversionSuccess']}\")\n",
    "logging.warning(f\"\\n# Failed audio conversion                    = {counters['countAudioConversionFailed']}\")\n",
    "logging.warning(f\"\\n# API calls made to Azure                    = {counters['countApiCallsMade']}\")\n",
    "logging.warning(f\"\\n# Characters processed                       = {overallCharCountTrack}\")\n",
    "logging.warning(f\"\\nProcessing return code                       = {processingReturnCode}\")\n",
    "logging.warning(f\"\\n  Status flag for 429 error                  = {flagRc429Encountered}\")\n",
    "#\n",
    "print(f\"\\n\\n\\nNormal exit\\n\")\n",
    "logging.warning(f\"\\n\\n\\nNormal exit\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Available voices: \n",
      "[\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ar-EG, Hoda)\",\n",
      "    \"ShortName\": \"ar-EG-Hoda\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ar-EG\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ar-SA, Naayf)\",\n",
      "    \"ShortName\": \"ar-SA-Naayf\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ar-SA\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (bg-BG, Ivan)\",\n",
      "    \"ShortName\": \"bg-BG-Ivan\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"bg-BG\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ca-ES, HerenaRUS)\",\n",
      "    \"ShortName\": \"ca-ES-HerenaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ca-ES\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (cs-CZ, Jakub)\",\n",
      "    \"ShortName\": \"cs-CZ-Jakub\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"cs-CZ\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (da-DK, HelleRUS)\",\n",
      "    \"ShortName\": \"da-DK-HelleRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"da-DK\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-AT, Michael)\",\n",
      "    \"ShortName\": \"de-AT-Michael\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"de-AT\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-CH, Karsten)\",\n",
      "    \"ShortName\": \"de-CH-Karsten\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"de-CH\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-DE, Hedda)\",\n",
      "    \"ShortName\": \"de-DE-Hedda\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"de-DE\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-DE, HeddaRUS)\",\n",
      "    \"ShortName\": \"de-DE-HeddaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"de-DE\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-DE, Stefan, Apollo)\",\n",
      "    \"ShortName\": \"de-DE-Stefan-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"de-DE\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (el-GR, Stefanos)\",\n",
      "    \"ShortName\": \"el-GR-Stefanos\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"el-GR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-AU, Catherine)\",\n",
      "    \"ShortName\": \"en-AU-Catherine\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-AU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-AU, HayleyRUS)\",\n",
      "    \"ShortName\": \"en-AU-HayleyRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-AU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-CA, Linda)\",\n",
      "    \"ShortName\": \"en-CA-Linda\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-CA\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-CA, HeatherRUS)\",\n",
      "    \"ShortName\": \"en-CA-HeatherRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-CA\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-GB, George, Apollo)\",\n",
      "    \"ShortName\": \"en-GB-George-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-GB\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-GB, HazelRUS)\",\n",
      "    \"ShortName\": \"en-GB-HazelRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-GB\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-GB, Susan, Apollo)\",\n",
      "    \"ShortName\": \"en-GB-Susan-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-GB\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-IE, Sean)\",\n",
      "    \"ShortName\": \"en-IE-Sean\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-IE\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-IN, Heera, Apollo)\",\n",
      "    \"ShortName\": \"en-IN-Heera-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-IN, PriyaRUS)\",\n",
      "    \"ShortName\": \"en-IN-PriyaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-IN, Ravi, Apollo)\",\n",
      "    \"ShortName\": \"en-IN-Ravi-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, BenjaminRUS)\",\n",
      "    \"ShortName\": \"en-US-BenjaminRUS\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, Guy24kRUS)\",\n",
      "    \"ShortName\": \"en-US-Guy24kRUS\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, JessaRUS)\",\n",
      "    \"ShortName\": \"en-US-JessaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, Jessa24kRUS)\",\n",
      "    \"ShortName\": \"en-US-Jessa24kRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, ZiraRUS)\",\n",
      "    \"ShortName\": \"en-US-ZiraRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (es-ES, HelenaRUS)\",\n",
      "    \"ShortName\": \"es-ES-HelenaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"es-ES\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (es-ES, Laura, Apollo)\",\n",
      "    \"ShortName\": \"es-ES-Laura-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"es-ES\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (es-ES, Pablo, Apollo)\",\n",
      "    \"ShortName\": \"es-ES-Pablo-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"es-ES\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (es-MX, HildaRUS)\",\n",
      "    \"ShortName\": \"es-MX-HildaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"es-MX\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (es-MX, Raul, Apollo)\",\n",
      "    \"ShortName\": \"es-MX-Raul-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"es-MX\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fi-FI, HeidiRUS)\",\n",
      "    \"ShortName\": \"fi-FI-HeidiRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fi-FI\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-CA, Caroline)\",\n",
      "    \"ShortName\": \"fr-CA-Caroline\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fr-CA\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-CA, HarmonieRUS)\",\n",
      "    \"ShortName\": \"fr-CA-HarmonieRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fr-CA\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-CH, Guillaume)\",\n",
      "    \"ShortName\": \"fr-CH-Guillaume\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"fr-CH\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-FR, HortenseRUS)\",\n",
      "    \"ShortName\": \"fr-FR-HortenseRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fr-FR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-FR, Julie, Apollo)\",\n",
      "    \"ShortName\": \"fr-FR-Julie-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fr-FR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-FR, Paul, Apollo)\",\n",
      "    \"ShortName\": \"fr-FR-Paul-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"fr-FR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (he-IL, Asaf)\",\n",
      "    \"ShortName\": \"he-IL-Asaf\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"he-IL\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (hi-IN, Hemant)\",\n",
      "    \"ShortName\": \"hi-IN-Hemant\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"hi-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (hi-IN, Kalpana, Apollo)\",\n",
      "    \"ShortName\": \"hi-IN-Kalpana-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"hi-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (hi-IN, Kalpana)\",\n",
      "    \"ShortName\": \"hi-IN-Kalpana\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"hi-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (hr-HR, Matej)\",\n",
      "    \"ShortName\": \"hr-HR-Matej\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"hr-HR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (hu-HU, Szabolcs)\",\n",
      "    \"ShortName\": \"hu-HU-Szabolcs\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"hu-HU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (id-ID, Andika)\",\n",
      "    \"ShortName\": \"id-ID-Andika\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"id-ID\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (it-IT, Cosimo, Apollo)\",\n",
      "    \"ShortName\": \"it-IT-Cosimo-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"it-IT\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (it-IT, LuciaRUS)\",\n",
      "    \"ShortName\": \"it-IT-LuciaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"it-IT\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ja-JP, Ayumi, Apollo)\",\n",
      "    \"ShortName\": \"ja-JP-Ayumi-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ja-JP\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ja-JP, HarukaRUS)\",\n",
      "    \"ShortName\": \"ja-JP-HarukaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ja-JP\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ja-JP, Ichiro, Apollo)\",\n",
      "    \"ShortName\": \"ja-JP-Ichiro-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ja-JP\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ko-KR, HeamiRUS)\",\n",
      "    \"ShortName\": \"ko-KR-HeamiRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ko-KR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ms-MY, Rizwan)\",\n",
      "    \"ShortName\": \"ms-MY-Rizwan\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ms-MY\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (nb-NO, HuldaRUS)\",\n",
      "    \"ShortName\": \"nb-NO-HuldaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"nb-NO\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (nl-NL, HannaRUS)\",\n",
      "    \"ShortName\": \"nl-NL-HannaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"nl-NL\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (pl-PL, PaulinaRUS)\",\n",
      "    \"ShortName\": \"pl-PL-PaulinaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"pl-PL\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (pt-BR, HeloisaRUS)\",\n",
      "    \"ShortName\": \"pt-BR-HeloisaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"pt-BR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (pt-BR, Daniel, Apollo)\",\n",
      "    \"ShortName\": \"pt-BR-Daniel-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"pt-BR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (pt-PT, HeliaRUS)\",\n",
      "    \"ShortName\": \"pt-PT-HeliaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"pt-PT\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ro-RO, Andrei)\",\n",
      "    \"ShortName\": \"ro-RO-Andrei\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ro-RO\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ru-RU, EkaterinaRUS)\",\n",
      "    \"ShortName\": \"ru-RU-EkaterinaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ru-RU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ru-RU, Irina, Apollo)\",\n",
      "    \"ShortName\": \"ru-RU-Irina-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"ru-RU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ru-RU, Pavel, Apollo)\",\n",
      "    \"ShortName\": \"ru-RU-Pavel-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ru-RU\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (sk-SK, Filip)\",\n",
      "    \"ShortName\": \"sk-SK-Filip\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"sk-SK\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (sl-SI, Lado)\",\n",
      "    \"ShortName\": \"sl-SI-Lado\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"sl-SI\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (sv-SE, HedvigRUS)\",\n",
      "    \"ShortName\": \"sv-SE-HedvigRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"sv-SE\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (ta-IN, Valluvar)\",\n",
      "    \"ShortName\": \"ta-IN-Valluvar\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"ta-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (te-IN, Chitra)\",\n",
      "    \"ShortName\": \"te-IN-Chitra\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"te-IN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (th-TH, Pattara)\",\n",
      "    \"ShortName\": \"th-TH-Pattara\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"th-TH\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (tr-TR, SedaRUS)\",\n",
      "    \"ShortName\": \"tr-TR-SedaRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"tr-TR\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (vi-VN, An)\",\n",
      "    \"ShortName\": \"vi-VN-An\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"vi-VN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-CN, HuihuiRUS)\",\n",
      "    \"ShortName\": \"zh-CN-HuihuiRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-CN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-CN, Kangkang, Apollo)\",\n",
      "    \"ShortName\": \"zh-CN-Kangkang-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"zh-CN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-CN, Yaoyao, Apollo)\",\n",
      "    \"ShortName\": \"zh-CN-Yaoyao-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-CN\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-HK, Tracy, Apollo)\",\n",
      "    \"ShortName\": \"zh-HK-Tracy-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-HK\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-HK, TracyRUS)\",\n",
      "    \"ShortName\": \"zh-HK-TracyRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-HK\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-HK, Danny, Apollo)\",\n",
      "    \"ShortName\": \"zh-HK-Danny-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"zh-HK\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-TW, HanHanRUS)\",\n",
      "    \"ShortName\": \"zh-TW-HanHanRUS\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-TW\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-TW, Yating, Apollo)\",\n",
      "    \"ShortName\": \"zh-TW-Yating-Apollo\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-TW\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-TW, Zhiwei, Apollo)\",\n",
      "    \"ShortName\": \"zh-TW-Zhiwei-Apollo\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"zh-TW\",\n",
      "    \"SampleRateHertz\": \"16000\",\n",
      "    \"VoiceType\": \"Standard\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, GuyNeural)\",\n",
      "    \"ShortName\": \"en-US-GuyNeural\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-US, JessaNeural)\",\n",
      "    \"ShortName\": \"en-US-JessaNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"en-US\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (zh-CN, XiaoxiaoNeural)\",\n",
      "    \"ShortName\": \"zh-CN-XiaoxiaoNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"zh-CN\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (it-IT, ElsaNeural)\",\n",
      "    \"ShortName\": \"it-IT-ElsaNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"it-IT\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (de-DE, KatjaNeural)\",\n",
      "    \"ShortName\": \"de-DE-KatjaNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"de-DE\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (en-GB, HarryNeural)\",\n",
      "    \"ShortName\": \"en-GB-HarryNeural\",\n",
      "    \"Gender\": \"Male\",\n",
      "    \"Locale\": \"en-GB\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (fr-FR, HortenseNeural)\",\n",
      "    \"ShortName\": \"fr-FR-HortenseNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"fr-FR\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  },\n",
      "  {\n",
      "    \"Name\": \"Microsoft Server Speech Text to Speech Voice (pt-BR, FranciscaNeural)\",\n",
      "    \"ShortName\": \"pt-BR-FranciscaNeural\",\n",
      "    \"Gender\": \"Female\",\n",
      "    \"Locale\": \"pt-BR\",\n",
      "    \"SampleRateHertz\": \"24000\",\n",
      "    \"VoiceType\": \"Neural\"\n",
      "  }\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "# Get a list of voices https://docs.microsoft.com/en-us/azure/cognitive-services/speech-service/rest-text-to-speech#get-a-list-of-voices\n",
    "app.get_voices_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
