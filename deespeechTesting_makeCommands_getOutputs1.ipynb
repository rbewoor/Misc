{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "##\n",
    "## VERY IMPORTANT:\n",
    "##     Logic assumes that --audio parameter is right at the end (after alphabet, lm, trie).\n",
    "##\n",
    "##     ---------------------------------------------\n",
    "##                   SECTION 1\n",
    "## Use this to create the Deepspeech inferernce commands first.\n",
    "##     Edit the parameters for:\n",
    "##          -- the Deepspeech command for model, lm, trie, alphabet.\n",
    "##          -- the output file.\n",
    "##          -- the audio file locations in the \"wavLocsDict\" dictionary.\n",
    "## Logic:\n",
    "##     Will populate the \"wavFilesDict\" dictionary with all the .wav files found in\n",
    "##          each of the locations specified in the \"wavLocsDict\" dictionary.\n",
    "##     Next will create the commands for each input .wav file and write all the\n",
    "##          commands to the output file specified.\n",
    "##          For each input .wav file, one command will be WITH language model and one\n",
    "##              for WITHOUT language model.\n",
    "##              Thus two commands per input .wav file.\n",
    "##\n",
    "##     ---------------------------------------------\n",
    "##                   SECTION 2\n",
    "## Use this to run each command, capture the output and write it all to a file.\n",
    "##     Edit the parameters for:\n",
    "##          -- the input command file.\n",
    "##          -- the output file.\n",
    "##          -- the flags to indicate which commands to run.\n",
    "##\n",
    "##     IMPORTANT: This section can be run independently of section 1.\n",
    "##          You can input an already created commands file.\n",
    "##          Else generate the commands using ection 1 and then run section 2.\n",
    "##\n",
    "## Logic:\n",
    "##     Reads in the commands file specified and creates two lists - for WITH and WITHOUT lm.\n",
    "##     Issues each command, captures the response and writes to output file.\n",
    "##     The output consists of the audio file name (from the command itself) and the output transcript.\n",
    "##\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "####    SECTION 1    ####    SECTION 1    ####    SECTION 1    ####\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "#\n",
    "class MyStopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## specify the location and filename where the commands generated should be written to.\n",
    "opFileLocationS1 = r'/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/'\n",
    "opFileNameS1 = r'section1op.txt'\n",
    "#\n",
    "## command skeleton\n",
    "cmd_skel = 'deepspeech'\n",
    "model_skel = '--model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb'\n",
    "alpha_skel = '--alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt'\n",
    "lm_skel = '--lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm'\n",
    "trie_skel = '--trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie'\n",
    "audio_skel = '--audio'\n",
    "#\n",
    "## specify the folder from where to look for the .wav files\n",
    "## make sure to put the / at end of each wavLocsDict folder entry\n",
    "wavLocsDict = {\n",
    "    'L1': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train',\n",
    "    'L2': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/',\n",
    "    'L3': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/'\n",
    "}\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'L1': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/', 'L2': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/', 'L3': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/'}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## add the slash at end of each folder location if its not there already.\n",
    "for key in wavLocsDict:\n",
    "    if wavLocsDict[key][-1] != '/':\n",
    "        wavLocsDict[key] += '/'\n",
    "print(f\"{wavLocsDict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "wavFiles dictionary is populated.\n",
      "\n",
      "\n",
      "{'L1': ['/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav', '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav'], 'L2': ['/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav', '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav'], 'L3': ['/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav', '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav']}\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## for each folder specified in the wavLocs dictionary, find the wav files in it and populate\n",
    "##     the wavFile dictionary.\n",
    "#\n",
    "wavFilesDict = {}\n",
    "for key in wavLocsDict:\n",
    "    #\n",
    "    ## make a list to hold the various .wav files. Use the same key as the current one from wavLocs.\n",
    "    wavFilesDict[key] = []\n",
    "    #\n",
    "    currLoc = wavLocsDict[key]\n",
    "    #print(f\"{currLoc}\")\n",
    "    ## if any of the folder locations specified is not found then stop everything.\n",
    "    if not os.path.isdir(currLoc):\n",
    "        print(f\"\\nFATAL ERROR: Folder location not found = {currLoc}\")\n",
    "        raise MyStopExecution\n",
    "    #\n",
    "    for eachWavFile in glob.glob(currLoc + '*.wav'):\n",
    "        #print(f\"\\t{eachWavFile}\")\n",
    "        wavFilesDict[key].append(eachWavFile) \n",
    "#\n",
    "for key in wavLocsDict:\n",
    "    wavFilesDict[key].sort()\n",
    "#\n",
    "print(f\"\\n\\nwavFiles dictionary is populated.\\n\\n\")\n",
    "print(f\"{wavFilesDict}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "The WITHOUT lm commands............\n",
      "\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav\n",
      "\n",
      "\n",
      "\n",
      "The WITH lm commands............\n",
      "\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav\n",
      "\n",
      "deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav\n",
      "\n",
      "\n",
      "\n",
      "Section 1 logic complete.\n",
      "\n",
      "Output file created here:\n",
      "/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/section1op.txt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## Generate the commands for WITH and WITHOUT language models and create the output file.\n",
    "## Each command will be written to one line.\n",
    "#\n",
    "opFileS1 = opFileLocationS1 + opFileNameS1\n",
    "#\n",
    "## command skeleton for both versions of the commands\n",
    "cmd_skeleton_NO_lm = cmd_skel + ' ' + model_skel + ' ' + alpha_skel + ' ' + audio_skel + ' '\n",
    "cmd_skeleton_WITH_lm = cmd_skel + ' ' + model_skel + ' ' + alpha_skel + ' ' + lm_skel + ' ' + trie_skel + ' ' + audio_skel + ' '\n",
    "#\n",
    "opCmdList_NO_lm   = []\n",
    "opCmdList_WITH_lm = []\n",
    "#\n",
    "for key in wavLocsDict:\n",
    "    for wavFile in wavFilesDict[key]:\n",
    "        opCmdList_NO_lm.append(cmd_skeleton_NO_lm + wavFile)\n",
    "        opCmdList_WITH_lm.append(cmd_skeleton_WITH_lm + wavFile)\n",
    "#\n",
    "## WITHOUT language model commands\n",
    "print(f\"\\n\\nThe WITHOUT lm commands............\\n\\n\")\n",
    "with open(opFileS1, 'w') as outF1:\n",
    "    for cmd in opCmdList_NO_lm:\n",
    "        print(f\"{cmd}\\n\")\n",
    "        outF1.write(cmd + '\\n')\n",
    "#\n",
    "## WITH language model commands\n",
    "print(f\"\\n\\nThe WITH lm commands............\\n\\n\")\n",
    "with open(opFileS1, 'a') as outF1:\n",
    "    for cmd in opCmdList_WITH_lm:\n",
    "        print(f\"{cmd}\\n\")\n",
    "        outF1.write(cmd + '\\n')\n",
    "#\n",
    "print(f\"\\n\\nSection 1 logic complete.\\n\\nOutput file created here:\\n{opFileS1}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "###################################################################\n",
    "####    SECTION 2    ####    SECTION 2    ####    SECTION 2    ####\n",
    "###################################################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import re\n",
    "import glob\n",
    "#\n",
    "class MyStopExecution(Exception):\n",
    "    def _render_traceback_(self):\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "## specify the location and filename from where to pick up the already generated commands.\n",
    "ipFileLocationS2 = r'/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/'\n",
    "ipFileNameS2 = r'section1op.txt'\n",
    "#\n",
    "## specify the location and filename where the outputs should be stored.\n",
    "opFileLocationS2 = r'/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/'\n",
    "opFileNameS2 = r'section2op.txt'\n",
    "#\n",
    "## set flag as True to run those types of commands\n",
    "flagRun_NOlm_cmds = True\n",
    "flagRun_WITHlm_cmds = True\n",
    "#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Commands WITHOUT lm:\n",
      "['deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav']\n",
      "\n",
      "Commands WITH lm:\n",
      "['deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav', 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --lm /home/rohit/dpspTraining/data/domainSet_1_20-260total/lm/lm4gram/vocab_domainSet1_20_260total_4gram.klm --trie /home/rohit/dpspTraining/data/domainSet_1_20-260total/trie/trie4gram/vocab_domainSet1_20_260total_4gram.trie --audio /home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav']\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## read the commands from the input file and put them into a list\n",
    "#\n",
    "ipFileS2 = ipFileLocationS2 + ipFileNameS2\n",
    "#\n",
    "opCmdList_NO_lm   = []\n",
    "opCmdList_WITH_lm = []\n",
    "#\n",
    "with open(ipFileS2, 'r') as inF2:\n",
    "    for line in inF2:\n",
    "        #print(f\"line less 1=\\n{line[:-1]}\")  ## remove the newline character\n",
    "        line = line[:-1]\n",
    "        ## add the with or without lm version of commands to the correct list\n",
    "        if '--lm ' in line:\n",
    "            opCmdList_WITH_lm.append(line)\n",
    "        else:\n",
    "            opCmdList_NO_lm.append(line)\n",
    "#\n",
    "print(f\"\\nCommands WITHOUT lm:\\n{opCmdList_NO_lm}\\n\\nCommands WITH lm:\\n{opCmdList_WITH_lm}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Data for WITHOUT lm:\n",
      "[{'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav', 'dsOpTran': 'or e  fls n nlle fo rl f toetll o or oriee t '}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav', 'dsOpTran': ' ro tes a n oarle  fon anennae formn ree at'}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav', 'dsOpTran': 'sstmmr ar oet ten e pld rrit aaooeoro ensvlo e t'}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav', 'dsOpTran': 'tsmrm  aptee le f teero ee tn re fon onet tenrai er aalle t '}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav', 'dsOpTran': 'sthe e oaa gt endal t e ees henn rnetin  elle  t ts'}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav', 'dsOpTran': 's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s '}]\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "Data for WITH lm:\n",
      "[{'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File1.wav', 'dsOpTran': 'for of as one for to to for are '}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/train/File2.wav', 'dsOpTran': 'the is a in are open are one a'}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File22.wav', 'dsOpTran': 'system to the and it a are not'}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/dev/File23.wav', 'dsOpTran': 'team a all of there in are one the a a all '}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File29.wav', 'dsOpTran': 'the a and a is when in all '}, {'audio': '/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/test/File30.wav', 'dsOpTran': 'some are as a roles one one in open are a '}]\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "onlyWavfileDsTranscriptNOlmList = []\n",
    "onlyWavfileDsTranscriptWITHlmList = []\n",
    "#\n",
    "## run the WITHOUT lm commands -- only if the flag is set true\n",
    "#\n",
    "if flagRun_NOlm_cmds:\n",
    "    dsFullResponseNOlmList = []\n",
    "    #\n",
    "    ## run each command and capture the full response, along with the filename used, in a list.\n",
    "    for currCmd in opCmdList_NO_lm:\n",
    "        tempAns = {'audio': 'xxx', 'dsOpTran': 'xxx'}\n",
    "        audioFile4mCmd = re.match(r\".+--audio (.+)$\", currCmd)\n",
    "        if len(audioFile4mCmd.groups()) == 1:  ## there should be only one audio file specified in command\n",
    "            audioFile4mCmd = audioFile4mCmd.groups()[0]\n",
    "            tempAns['audio']= audioFile4mCmd\n",
    "        else:\n",
    "            print(f\"\\nFatal Error: Regex match to find audio file failed. Should have found exactly 1 match. But found = {len(audioFile4mCmd.groups())}\\n\")\n",
    "            raise MyStopExecution\n",
    "        #\n",
    "        tempAns['dsOpTran']= %sx $currCmd\n",
    "        dsFullResponseNOlmList.append(tempAns)\n",
    "    #\n",
    "    ## from each response extract only the transcript and store with the filename used in command into new list.\n",
    "    for response in dsFullResponseNOlmList:\n",
    "        tempAns = {}\n",
    "        tempAns['audio'] = response['audio']\n",
    "        if response['dsOpTran'][-2].startswith('Inference took'):\n",
    "            tempAns['dsOpTran'] = response['dsOpTran'][-1]\n",
    "        else:\n",
    "            tempAns['dsOpTran'] = 'PROBLEM WITH DS OUTPUT'\n",
    "        onlyWavfileDsTranscriptNOlmList.append(tempAns)\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print(f\"\\n\\nData for WITHOUT lm:\\n{onlyWavfileDsTranscriptNOlmList}\\n\\n\")\n",
    "#\n",
    "## run the WITH lm commands -- only if the flag is set true\n",
    "#\n",
    "if flagRun_WITHlm_cmds:\n",
    "    dsFullResponseWITHlmList = []\n",
    "    #\n",
    "    ## run each command and capture the full response, along with the filename used, in a list.\n",
    "    for currCmd in opCmdList_WITH_lm:\n",
    "        tempAns = {'audio': 'xxx', 'dsOpTran': 'xxx'}\n",
    "        audioFile4mCmd = re.match(r\".+--audio (.+)$\", currCmd)\n",
    "        if len(audioFile4mCmd.groups()) == 1:  ## there should be only one audio file specified in command\n",
    "            audioFile4mCmd = audioFile4mCmd.groups()[0]\n",
    "            tempAns['audio']= audioFile4mCmd\n",
    "        else:\n",
    "            print(f\"\\nFatal Error: Regex match to find audio file failed. Should have found exactly 1 match. But found = {len(audioFile4mCmd.groups())}\\n\")\n",
    "            raise MyStopExecution\n",
    "        #\n",
    "        tempAns['dsOpTran']= %sx $currCmd\n",
    "        dsFullResponseWITHlmList.append(tempAns)\n",
    "    #\n",
    "    ## from each response extract only the transcript and store with the filename used in command into new list.\n",
    "    for response in dsFullResponseWITHlmList:\n",
    "        tempAns = {}\n",
    "        tempAns['audio'] = response['audio']\n",
    "        if response['dsOpTran'][-2].startswith('Inference took'):\n",
    "            tempAns['dsOpTran'] = response['dsOpTran'][-1]\n",
    "        else:\n",
    "            tempAns['dsOpTran'] = 'PROBLEM WITH DS OUTPUT'\n",
    "        onlyWavfileDsTranscriptWITHlmList.append(tempAns)\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print(f\"\\n\\nData for WITH lm:\\n{onlyWavfileDsTranscriptWITHlmList}\\n\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Section 2 logic complete.\n",
      "\n",
      "Output file created here:\n",
      "/home/rohit/dpspTraining/data/domainSet_1_20-260total/OutputTesting/section2op.txt\n"
     ]
    }
   ],
   "source": [
    "#\n",
    "## write the output file\n",
    "#\n",
    "opFileS2 = opFileLocationS2 + opFileNameS2\n",
    "#\n",
    "with open(opFileS2, 'w') as outF2:\n",
    "    lineOut = ' --------- WITHOUT language model --------- \\n\\n'\n",
    "    outF2.write(lineOut)\n",
    "    if len(onlyWavfileDsTranscriptNOlmList) == 0:\n",
    "        lineOut = 'No data to write\\n\\n'\n",
    "        outF2.write(lineOut)\n",
    "    else:\n",
    "        for response in onlyWavfileDsTranscriptNOlmList:\n",
    "            lineOut = response['audio'] + '\\n' + response['dsOpTran'] + '\\n'\n",
    "            outF2.write(lineOut)\n",
    "        #\n",
    "    #\n",
    "    lineOut = '\\n\\n ---------- WITH language model ---------- \\n\\n'\n",
    "    outF2.write(lineOut)\n",
    "    if len(onlyWavfileDsTranscriptWITHlmList) == 0:\n",
    "        lineOut = 'No data to write\\n\\n'\n",
    "        outF2.write(lineOut)\n",
    "    else:\n",
    "        for response in onlyWavfileDsTranscriptWITHlmList:\n",
    "            lineOut = response['audio'] + '\\n' + response['dsOpTran'] + '\\n'\n",
    "            outF2.write(lineOut)\n",
    "        #\n",
    "    #\n",
    "#\n",
    "print(f\"\\n\\nSection 2 logic complete.\\n\\nOutput file created here:\\n{opFileS2}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/train/File10.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/dev/File27.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/dev/File33.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File29.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav']"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opCmdList_NO_lm_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opCmdList_NO_lm_one[4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmd2Run = opCmdList_NO_lm_one[4]\n",
    "cmd2Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       " 'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       " 'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       " '2019-12-13 22:09:33.261472: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " '2019-12-13 22:09:33.303226: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " '2019-12-13 22:09:33.303308: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 22:09:33.303334: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 22:09:33.303518: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " 'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       " 'Loaded model in 0.0817s.',\n",
       " 'Running inference.',\n",
       " 'Inference took 1.395s for 5.641s audio file.',\n",
       " 's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s ']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## run it directly\n",
    "%sx $cmd2Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## run it but save the answer\n",
    "dsResp = %sx $cmd2Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.utils.text.SList"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsResp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       " 'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       " 'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       " '2019-12-13 22:09:36.982745: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " '2019-12-13 22:09:36.993622: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " '2019-12-13 22:09:36.993696: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 22:09:36.993729: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 22:09:36.993859: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " 'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       " 'Loaded model in 0.0151s.',\n",
       " 'Running inference.',\n",
       " 'Inference took 0.994s for 5.641s audio file.',\n",
       " 's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s ']"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsResp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsResp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'s mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s '"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsResp[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "str"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsResp[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/train/File10.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/dev/File27.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/dev/File33.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File29.wav',\n",
       " 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav']"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "opCmdList_NO_lm_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re, os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done\n"
     ]
    }
   ],
   "source": [
    "dsAnsList = []\n",
    "for eachCmd in opCmdList_NO_lm_one:\n",
    "    tempAns = {'audio': 'xxx', 'dsOpTran': 'xxx'}\n",
    "    audioFile4mCmd = re.match(r\".+--audio (.+)$\", eachCmd)\n",
    "    if len(audioFile4mCmd.groups()) == 1:\n",
    "        audioFile4mCmd = audioFile4mCmd.groups()[0]\n",
    "        tempAns['audio']= audioFile4mCmd\n",
    "    else:\n",
    "        print(f\"\\nFatal Error: Regex match to find audio file failed. Should have found exactly 1 match. But found = {len(audioFile4mCmd.groups())}\\n\")\n",
    "        break\n",
    "    tempAns['dsOpTran']= %sx $eachCmd\n",
    "    dsAnsList.append(tempAns)\n",
    "print(f\"Done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFile4mCmd = re.match(r\".+--audio (.+)$\", cmdstr)\n",
    "if audioFile4mCmd:\n",
    "    print(f\"{audioFile4mCmd.groups()}\")\n",
    "    for audioFile in audioFile4mCmd.groups():\n",
    "        if os.path.isfile(audioFile):\n",
    "            print(f\"{audioFile} IS A FILE -- ALL OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio': '/home/rohit/dpspTraining/data/wav33/train/File10.wav',\n",
       "  'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "   'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "   'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "   '2019-12-13 22:45:58.757440: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "   '2019-12-13 22:45:58.768720: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   '2019-12-13 22:45:58.768796: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:45:58.768830: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:45:58.768961: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "   'Loaded model in 0.0144s.',\n",
       "   'Running inference.',\n",
       "   'Inference took 0.769s for 3.286s audio file.',\n",
       "   'or amarn ert a plre ae col or aearlt']},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/dev/File27.wav',\n",
       "  'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "   'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "   'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "   '2019-12-13 22:45:59.696194: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "   '2019-12-13 22:45:59.707390: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   '2019-12-13 22:45:59.707465: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:45:59.707500: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:45:59.707632: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "   'Loaded model in 0.0176s.',\n",
       "   'Running inference.',\n",
       "   'Inference took 0.815s for 3.898s audio file.',\n",
       "   's ormr priena theellt eros te mritevoro e pallle t ']},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/dev/File33.wav',\n",
       "  'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "   'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "   'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "   '2019-12-13 22:46:00.683363: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "   '2019-12-13 22:46:00.694470: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   '2019-12-13 22:46:00.694546: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:00.694581: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:00.694709: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "   'Loaded model in 0.0145s.',\n",
       "   'Running inference.',\n",
       "   'Inference took 0.794s for 3.634s audio file.',\n",
       "   'tem f eaiseh ors ho ee ssfansysteee  s']},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/test/File29.wav',\n",
       "  'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "   'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "   'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "   '2019-12-13 22:46:01.647962: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "   '2019-12-13 22:46:01.659255: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   '2019-12-13 22:46:01.659332: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:01.659366: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:01.659499: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "   'Loaded model in 0.0179s.',\n",
       "   'Running inference.',\n",
       "   'Inference took 0.857s for 4.234s audio file.',\n",
       "   'sthe e oaa gt endal t e ees henn rnetin  elle  t ts']},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/test/File30.wav',\n",
       "  'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "   'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "   'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "   '2019-12-13 22:46:02.677132: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "   '2019-12-13 22:46:02.688258: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   '2019-12-13 22:46:02.688337: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:02.688372: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "   '2019-12-13 22:46:02.688503: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "   'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "   'Loaded model in 0.0155s.',\n",
       "   'Running inference.',\n",
       "   'Inference took 0.990s for 5.641s audio file.',\n",
       "   's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s ']}]"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsAnsList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dsAnsList)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'audio': '/home/rohit/dpspTraining/data/wav33/train/File10.wav',\n",
       " 'dsOpTran': ['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       "  'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       "  'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       "  '2019-12-13 22:45:58.757440: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       "  '2019-12-13 22:45:58.768720: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "  '2019-12-13 22:45:58.768796: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       "  '2019-12-13 22:45:58.768830: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       "  '2019-12-13 22:45:58.768961: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       "  'Loading model from file /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb',\n",
       "  'Loaded model in 0.0144s.',\n",
       "  'Running inference.',\n",
       "  'Inference took 0.769s for 3.286s audio file.',\n",
       "  'or amarn ert a plre ae col or aearlt']}"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsAnsList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalAns = []\n",
    "for eachDsAns in dsAnsList:\n",
    "    tempFinalAns = {}\n",
    "    tempFinalAns['audio'] = eachDsAns['audio']\n",
    "    if eachDsAns['dsOpTran'][-2].startswith('Inference took'):\n",
    "        tempFinalAns['dsOpTran'] = eachDsAns['dsOpTran'][-1]\n",
    "    else:\n",
    "        tempFinalAns['dsOpTran'] = 'PROBLEM WITH DS OUTPUT'\n",
    "    finalAns.append(tempFinalAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'audio': '/home/rohit/dpspTraining/data/wav33/train/File10.wav',\n",
       "  'dsOpTran': 'or amarn ert a plre ae col or aearlt'},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/dev/File27.wav',\n",
       "  'dsOpTran': 's ormr priena theellt eros te mritevoro e pallle t '},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/dev/File33.wav',\n",
       "  'dsOpTran': 'tem f eaiseh ors ho ee ssfansysteee  s'},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/test/File29.wav',\n",
       "  'dsOpTran': 'sthe e oaa gt endal t e ees henn rnetin  elle  t ts'},\n",
       " {'audio': '/home/rohit/dpspTraining/data/wav33/test/File30.wav',\n",
       "  'dsOpTran': 's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s '}]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "finalAns = []\n",
    "for i in range(len(dsAnsList)):\n",
    "    finalAns.append(dsAnsList[i][-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['or amarn ert a plre ae col or aearlt',\n",
       " 's ormr priena theellt eros te mritevoro e pallle t ',\n",
       " 'tem f eaiseh ors ho ee ssfansysteee  s',\n",
       " 'sthe e oaa gt endal t e ees henn rnetin  elle  t ts',\n",
       " 's mm rieit ons albmamtarllle ts wrnraie ormtae eind opalle an e rle a s ']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "finalAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = 'rohitbewoor'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a.startswith('ro')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rohit/dpspTraining/myCode']"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "someCmd = 'pwd'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/bin/sh: 1: someCmd: not found\r\n"
     ]
    }
   ],
   "source": [
    "!someCmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bin/bash: someCmd: command not found']"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx someCmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://stackoverflow.com/questions/14409167/how-to-pass-a-variable-to-magic-%C2%B4run%C2%B4-function-in-ipython"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rohit/dpspTraining/myCode']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx $someCmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to run shell commands and capture the output.\n",
    "cmdList = ['pwd']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['pwd']"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmdList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pwd'"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmdList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/bin/bash: [pwd][0]: command not found']"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx $cmdList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx ${cmdList[0]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "## trying to run shell commands and capture the output.\n",
    "cmdList = ['pwd']\n",
    "actualCmd = cmdList[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'pwd'"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "actualCmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['/home/rohit/dpspTraining/myCode']"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%sx $actualCmd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-42-3c89609078d3>, line 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-42-3c89609078d3>\"\u001b[0;36m, line \u001b[0;32m3\u001b[0m\n\u001b[0;31m    testList.append(%sx $actualCmd)\u001b[0m\n\u001b[0m                    ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "testList = []\n",
    "for i in range(3):\n",
    "    testList.append(%sx $actualCmd)\n",
    "print(f\"{testList}\")\n",
    "print(f\"{type(testList)}\")\n",
    "print(f\"{type(testList[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['/home/rohit/dpspTraining/myCode'], ['/home/rohit/dpspTraining/myCode'], ['/home/rohit/dpspTraining/myCode']]\n",
      "<class 'list'>\n",
      "<class 'IPython.utils.text.SList'>\n"
     ]
    }
   ],
   "source": [
    "testList = []\n",
    "for i in range(3):\n",
    "    tempAns = %sx $actualCmd\n",
    "    testList.append(tempAns)\n",
    "print(f\"{testList}\")\n",
    "print(f\"{type(testList)}\")\n",
    "print(f\"{type(testList[0])}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from file /home/rohit/dpspTraining/models/v051/model11-domainSet1-pdf1_1_950/savedModel/output_graph_afterPDF1_20191212_1510.pb\n",
      "TensorFlow: v1.13.1-10-g3e0cc53\n",
      "DeepSpeech: v0.5.1-0-g4b29b78\n",
      "Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.\n",
      "2019-12-13 16:34:19.295033: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA\n",
      "2019-12-13 16:34:19.379159: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"CPU\"') for unknown op: UnwrapDatasetVariant\n",
      "2019-12-13 16:34:19.379188: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: WrapDatasetVariant\n",
      "2019-12-13 16:34:19.379195: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"WrapDatasetVariant\" device_type: \"CPU\"') for unknown op: WrapDatasetVariant\n",
      "2019-12-13 16:34:19.379260: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel ('op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"') for unknown op: UnwrapDatasetVariant\n",
      "Loaded model in 0.0856s.\n",
      "Running inference.\n",
      "the palor is nomally log munday orly drink ucop an donor ethtup\n",
      "Inference took 4.385s for 5.641s audio file.\n"
     ]
    }
   ],
   "source": [
    "!deepspeech --model /home/rohit/dpspTraining/models/v051/model11-domainSet1-pdf1_1_950/savedModel/output_graph_afterPDF1_20191212_1510.pb --alphabet /home/rohit/dpspTraining/data/wavFiles/domainSet1-pdf1_1_950/alphabetDir/alpha_combined_PDF1.txt --audio /home/rohit/dpspTraining/data/wavFiles/wav33/test/File30.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## https://jakevdp.github.io/PythonDataScienceHandbook/01.05-ipython-and-shell-commands.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "dsAns = !deepspeech --model /home/rohit/dpspTraining/models/v051/model11-domainSet1-pdf1_1_950/savedModel/output_graph_afterPDF1_20191212_1510.pb --alphabet /home/rohit/dpspTraining/data/wavFiles/domainSet1-pdf1_1_950/alphabetDir/alpha_combined_PDF1.txt --audio /home/rohit/dpspTraining/data/wavFiles/wav33/test/File30.wav"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "IPython.utils.text.SList"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(dsAns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['TensorFlow: v1.13.1-10-g3e0cc53',\n",
       " 'DeepSpeech: v0.5.1-0-g4b29b78',\n",
       " 'Warning: reading entire model file into memory. Transform model file into an mmapped graph to reduce heap usage.',\n",
       " '2019-12-13 17:09:23.573875: I tensorflow/core/platform/cpu_feature_guard.cc:141] Your CPU supports instructions that this TensorFlow binary was not compiled to use: AVX2 FMA',\n",
       " '2019-12-13 17:09:23.658355: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " '2019-12-13 17:09:23.658381: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 17:09:23.658387: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"WrapDatasetVariant\" device_type: \"CPU\"\\') for unknown op: WrapDatasetVariant',\n",
       " '2019-12-13 17:09:23.658451: E tensorflow/core/framework/op_kernel.cc:1325] OpKernel (\\'op: \"UnwrapDatasetVariant\" device_type: \"GPU\" host_memory_arg: \"input_handle\" host_memory_arg: \"output_handle\"\\') for unknown op: UnwrapDatasetVariant',\n",
       " 'Loading model from file /home/rohit/dpspTraining/models/v051/model11-domainSet1-pdf1_1_950/savedModel/output_graph_afterPDF1_20191212_1510.pb',\n",
       " 'Loaded model in 0.086s.',\n",
       " 'Running inference.',\n",
       " 'Inference took 4.438s for 5.641s audio file.',\n",
       " 'the palor is nomally log munday orly drink ucop an donor ethtup']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dsAns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####################################\n",
    "####################################\n",
    "####################################\n",
    "####################################"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## pull out the audio file name from command"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav'"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cmdstr = 'deepspeech --model /home/rohit/dpspTraining/models/v051/model2-domainSet_1_20-260total/savedModelDir/output_graph.pb --alphabet /home/rohit/dpspTraining/data/domainSet_1_20-260total/alphabetDir/alpha_domainSet1_20_260total.txt --audio /home/rohit/dpspTraining/data/wav33/test/File30.wav'\n",
    "cmdstr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "audioFile4mCmd = re.match(r\".+--audio (.+)$\", cmdstr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('/home/rohit/dpspTraining/data/wav33/test/File30.wav',)\n",
      "/home/rohit/dpspTraining/data/wav33/test/File30.wav IS A FILE -- ALL OK.\n"
     ]
    }
   ],
   "source": [
    "if audioFile4mCmd:\n",
    "    print(f\"{audioFile4mCmd.groups()}\")\n",
    "    for audioFile in audioFile4mCmd.groups():\n",
    "        if os.path.isfile(audioFile):\n",
    "            print(f\"{audioFile} IS A FILE -- ALL OK.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(audioFile4mCmd.groups())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'/home/rohit/dpspTraining/data/wav33/test/File30.wav'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "audioFile4mCmd.groups()[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
